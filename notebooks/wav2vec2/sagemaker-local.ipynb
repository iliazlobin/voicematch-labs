{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS_PROFILE: iliazlobin-gpt\n"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "import os\n",
    "\n",
    "# dotenv.load_dotenv(\"/root/ws/ml/.env\", override=True)\n",
    "\n",
    "print('AWS_PROFILE:', os.environ.get('AWS_PROFILE'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.local import LocalSession\n",
    "\n",
    "sagemaker_session = LocalSession()\n",
    "sagemaker_session.config = {'local': {'local_code': True}}\n",
    "\n",
    "# pass sagemaker_session to your estimator or model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoCredentialsError",
     "evalue": "Unable to locate credentials",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoCredentialsError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msagemaker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlocal\u001b[39;00m \u001b[39mimport\u001b[39;00m LocalSession\n\u001b[1;32m      4\u001b[0m sess \u001b[39m=\u001b[39m LocalSession()\n\u001b[0;32m----> 5\u001b[0m role \u001b[39m=\u001b[39m sagemaker\u001b[39m.\u001b[39;49mget_execution_role()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-experiments/lib/python3.10/site-packages/sagemaker/session.py:5429\u001b[0m, in \u001b[0;36mget_execution_role\u001b[0;34m(sagemaker_session)\u001b[0m\n\u001b[1;32m   5427\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m sagemaker_session:\n\u001b[1;32m   5428\u001b[0m     sagemaker_session \u001b[39m=\u001b[39m Session()\n\u001b[0;32m-> 5429\u001b[0m arn \u001b[39m=\u001b[39m sagemaker_session\u001b[39m.\u001b[39;49mget_caller_identity_arn()\n\u001b[1;32m   5431\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m:role/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m arn:\n\u001b[1;32m   5432\u001b[0m     \u001b[39mreturn\u001b[39;00m arn\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-experiments/lib/python3.10/site-packages/sagemaker/session.py:4067\u001b[0m, in \u001b[0;36mSession.get_caller_identity_arn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4056\u001b[0m     \u001b[39mexcept\u001b[39;00m ClientError:\n\u001b[1;32m   4057\u001b[0m         LOGGER\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m   4058\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt call \u001b[39m\u001b[39m'\u001b[39m\u001b[39mdescribe_notebook_instance\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to get the Role \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4059\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mARN of the instance \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   4060\u001b[0m             instance_name,\n\u001b[1;32m   4061\u001b[0m         )\n\u001b[1;32m   4063\u001b[0m assumed_role \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mboto_session\u001b[39m.\u001b[39;49mclient(\n\u001b[1;32m   4064\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39msts\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   4065\u001b[0m     region_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mboto_region_name,\n\u001b[1;32m   4066\u001b[0m     endpoint_url\u001b[39m=\u001b[39;49msts_regional_endpoint(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mboto_region_name),\n\u001b[0;32m-> 4067\u001b[0m )\u001b[39m.\u001b[39;49mget_caller_identity()[\u001b[39m\"\u001b[39m\u001b[39mArn\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   4069\u001b[0m role \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m^(.+)sts::(\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+):assumed-role/(.+?)/.*$\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m1iam::\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m2:role/\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m3\u001b[39m\u001b[39m\"\u001b[39m, assumed_role)\n\u001b[1;32m   4071\u001b[0m \u001b[39m# Call IAM to get the role's path\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-experiments/lib/python3.10/site-packages/botocore/client.py:530\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    527\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpy_operation_name\u001b[39m}\u001b[39;00m\u001b[39m() only accepts keyword arguments.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[1;32m    529\u001b[0m \u001b[39m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 530\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_api_call(operation_name, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-experiments/lib/python3.10/site-packages/botocore/client.py:943\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    942\u001b[0m     apply_request_checksum(request_dict)\n\u001b[0;32m--> 943\u001b[0m     http, parsed_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    944\u001b[0m         operation_model, request_dict, request_context\n\u001b[1;32m    945\u001b[0m     )\n\u001b[1;32m    947\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mevents\u001b[39m.\u001b[39memit(\n\u001b[1;32m    948\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mafter-call.\u001b[39m\u001b[39m{service_id}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{operation_name}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    949\u001b[0m         service_id\u001b[39m=\u001b[39mservice_id, operation_name\u001b[39m=\u001b[39moperation_name\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    954\u001b[0m     context\u001b[39m=\u001b[39mrequest_context,\n\u001b[1;32m    955\u001b[0m )\n\u001b[1;32m    957\u001b[0m \u001b[39mif\u001b[39;00m http\u001b[39m.\u001b[39mstatus_code \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m300\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-experiments/lib/python3.10/site-packages/botocore/client.py:966\u001b[0m, in \u001b[0;36mBaseClient._make_request\u001b[0;34m(self, operation_model, request_dict, request_context)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_request\u001b[39m(\u001b[39mself\u001b[39m, operation_model, request_dict, request_context):\n\u001b[1;32m    965\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 966\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_endpoint\u001b[39m.\u001b[39;49mmake_request(operation_model, request_dict)\n\u001b[1;32m    967\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    968\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mevents\u001b[39m.\u001b[39memit(\n\u001b[1;32m    969\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mafter-call-error.\u001b[39m\u001b[39m{service_id}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{operation_name}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    970\u001b[0m                 service_id\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_service_model\u001b[39m.\u001b[39mservice_id\u001b[39m.\u001b[39mhyphenize(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    974\u001b[0m             context\u001b[39m=\u001b[39mrequest_context,\n\u001b[1;32m    975\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-experiments/lib/python3.10/site-packages/botocore/endpoint.py:119\u001b[0m, in \u001b[0;36mEndpoint.make_request\u001b[0;34m(self, operation_model, request_dict)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_request\u001b[39m(\u001b[39mself\u001b[39m, operation_model, request_dict):\n\u001b[1;32m    114\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m    115\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMaking request for \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m with params: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    116\u001b[0m         operation_model,\n\u001b[1;32m    117\u001b[0m         request_dict,\n\u001b[1;32m    118\u001b[0m     )\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(request_dict, operation_model)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-experiments/lib/python3.10/site-packages/botocore/endpoint.py:198\u001b[0m, in \u001b[0;36mEndpoint._send_request\u001b[0;34m(self, request_dict, operation_model)\u001b[0m\n\u001b[1;32m    196\u001b[0m context \u001b[39m=\u001b[39m request_dict[\u001b[39m'\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    197\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_retries_context(context, attempts)\n\u001b[0;32m--> 198\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_request(request_dict, operation_model)\n\u001b[1;32m    199\u001b[0m success_response, exception \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_response(\n\u001b[1;32m    200\u001b[0m     request, operation_model, context\n\u001b[1;32m    201\u001b[0m )\n\u001b[1;32m    202\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_needs_retry(\n\u001b[1;32m    203\u001b[0m     attempts,\n\u001b[1;32m    204\u001b[0m     operation_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m     exception,\n\u001b[1;32m    208\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-experiments/lib/python3.10/site-packages/botocore/endpoint.py:134\u001b[0m, in \u001b[0;36mEndpoint.create_request\u001b[0;34m(self, params, operation_model)\u001b[0m\n\u001b[1;32m    130\u001b[0m     service_id \u001b[39m=\u001b[39m operation_model\u001b[39m.\u001b[39mservice_model\u001b[39m.\u001b[39mservice_id\u001b[39m.\u001b[39mhyphenize()\n\u001b[1;32m    131\u001b[0m     event_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrequest-created.\u001b[39m\u001b[39m{service_id}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{op_name}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    132\u001b[0m         service_id\u001b[39m=\u001b[39mservice_id, op_name\u001b[39m=\u001b[39moperation_model\u001b[39m.\u001b[39mname\n\u001b[1;32m    133\u001b[0m     )\n\u001b[0;32m--> 134\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event_emitter\u001b[39m.\u001b[39;49memit(\n\u001b[1;32m    135\u001b[0m         event_name,\n\u001b[1;32m    136\u001b[0m         request\u001b[39m=\u001b[39;49mrequest,\n\u001b[1;32m    137\u001b[0m         operation_name\u001b[39m=\u001b[39;49moperation_model\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    138\u001b[0m     )\n\u001b[1;32m    139\u001b[0m prepared_request \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_request(request)\n\u001b[1;32m    140\u001b[0m \u001b[39mreturn\u001b[39;00m prepared_request\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-experiments/lib/python3.10/site-packages/botocore/hooks.py:412\u001b[0m, in \u001b[0;36mEventAliaser.emit\u001b[0;34m(self, event_name, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39memit\u001b[39m(\u001b[39mself\u001b[39m, event_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    411\u001b[0m     aliased_event_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_alias_event_name(event_name)\n\u001b[0;32m--> 412\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_emitter\u001b[39m.\u001b[39;49memit(aliased_event_name, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-experiments/lib/python3.10/site-packages/botocore/hooks.py:256\u001b[0m, in \u001b[0;36mHierarchicalEmitter.emit\u001b[0;34m(self, event_name, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39memit\u001b[39m(\u001b[39mself\u001b[39m, event_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    246\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[39m    Emit an event by name with arguments passed as keyword args.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39m             handlers.\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_emit(event_name, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-experiments/lib/python3.10/site-packages/botocore/hooks.py:239\u001b[0m, in \u001b[0;36mHierarchicalEmitter._emit\u001b[0;34m(self, event_name, kwargs, stop_on_response)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers_to_call:\n\u001b[1;32m    238\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39m'\u001b[39m\u001b[39mEvent \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: calling handler \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m, event_name, handler)\n\u001b[0;32m--> 239\u001b[0m     response \u001b[39m=\u001b[39m handler(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    240\u001b[0m     responses\u001b[39m.\u001b[39mappend((handler, response))\n\u001b[1;32m    241\u001b[0m     \u001b[39mif\u001b[39;00m stop_on_response \u001b[39mand\u001b[39;00m response \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-experiments/lib/python3.10/site-packages/botocore/signers.py:105\u001b[0m, in \u001b[0;36mRequestSigner.handler\u001b[0;34m(self, operation_name, request, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhandler\u001b[39m(\u001b[39mself\u001b[39m, operation_name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, request\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    101\u001b[0m     \u001b[39m# This is typically hooked up to the \"request-created\" event\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \u001b[39m# from a client's event emitter.  When a new request is created\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     \u001b[39m# this method is invoked to sign the request.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     \u001b[39m# Don't call this method directly.\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msign(operation_name, request)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-experiments/lib/python3.10/site-packages/botocore/signers.py:189\u001b[0m, in \u001b[0;36mRequestSigner.sign\u001b[0;34m(self, operation_name, request, region_name, signing_type, expires_in, signing_name)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m--> 189\u001b[0m auth\u001b[39m.\u001b[39;49madd_auth(request)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-experiments/lib/python3.10/site-packages/botocore/auth.py:418\u001b[0m, in \u001b[0;36mSigV4Auth.add_auth\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd_auth\u001b[39m(\u001b[39mself\u001b[39m, request):\n\u001b[1;32m    417\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcredentials \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 418\u001b[0m         \u001b[39mraise\u001b[39;00m NoCredentialsError()\n\u001b[1;32m    419\u001b[0m     datetime_now \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mutcnow()\n\u001b[1;32m    420\u001b[0m     request\u001b[39m.\u001b[39mcontext[\u001b[39m'\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m datetime_now\u001b[39m.\u001b[39mstrftime(SIGV4_TIMESTAMP)\n",
      "\u001b[0;31mNoCredentialsError\u001b[0m: Unable to locate credentials"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.local import LocalSession\n",
    "\n",
    "sess = LocalSession()\n",
    "role = sagemaker.get_execution_role()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.local import LocalSession\n",
    "\n",
    "iam_client = boto3.client('iam')\n",
    "role = iam_client.get_role(\n",
    "    RoleName=\"sagemaker-local-role\")['Role']['Arn']\n",
    "sess = LocalSession()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS_PROFILE: iliazlobin-gpt\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the CreateModel operation: Could not access model data at s3://aws-ml-blog/artifacts/pytorch-script-mode-local-model-inference/model.tar.gz. Please ensure that the role \"arn:aws:iam::908060038426:role/sagemaker-local-role\" exists and that its trust relationship policy allows the action \"sts:AssumeRole\" for the service principal \"sagemaker.amazonaws.com\". Also ensure that the role has \"s3:GetObject\" permissions and that the object is located in us-east-1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 33\u001b[0m\n\u001b[1;32m     21\u001b[0m model \u001b[39m=\u001b[39m HuggingFaceModel(\n\u001b[1;32m     22\u001b[0m     transformers_version\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m4.17\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     23\u001b[0m     pytorch_version\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m1.10\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[39m# sagemaker_session=sess,\u001b[39;00m\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[39m# deploy model to SageMaker Inference\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m predictor \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdeploy(\n\u001b[1;32m     34\u001b[0m     initial_instance_count\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     35\u001b[0m     instance_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlocal\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     36\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-experiments/lib/python3.10/site-packages/sagemaker/huggingface/model.py:308\u001b[0m, in \u001b[0;36mHuggingFaceModel.deploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, async_inference_config, serverless_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, inference_recommendation_id, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_uri \u001b[39mand\u001b[39;00m instance_type \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m instance_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mml.inf\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    303\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_uri \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mserving_image_uri(\n\u001b[1;32m    304\u001b[0m         region_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msagemaker_session\u001b[39m.\u001b[39mboto_session\u001b[39m.\u001b[39mregion_name,\n\u001b[1;32m    305\u001b[0m         instance_type\u001b[39m=\u001b[39minstance_type,\n\u001b[1;32m    306\u001b[0m     )\n\u001b[0;32m--> 308\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(HuggingFaceModel, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mdeploy(\n\u001b[1;32m    309\u001b[0m     initial_instance_count,\n\u001b[1;32m    310\u001b[0m     instance_type,\n\u001b[1;32m    311\u001b[0m     serializer,\n\u001b[1;32m    312\u001b[0m     deserializer,\n\u001b[1;32m    313\u001b[0m     accelerator_type,\n\u001b[1;32m    314\u001b[0m     endpoint_name,\n\u001b[1;32m    315\u001b[0m     tags,\n\u001b[1;32m    316\u001b[0m     kms_key,\n\u001b[1;32m    317\u001b[0m     wait,\n\u001b[1;32m    318\u001b[0m     data_capture_config,\n\u001b[1;32m    319\u001b[0m     async_inference_config,\n\u001b[1;32m    320\u001b[0m     serverless_inference_config,\n\u001b[1;32m    321\u001b[0m     volume_size\u001b[39m=\u001b[39;49mvolume_size,\n\u001b[1;32m    322\u001b[0m     model_data_download_timeout\u001b[39m=\u001b[39;49mmodel_data_download_timeout,\n\u001b[1;32m    323\u001b[0m     container_startup_health_check_timeout\u001b[39m=\u001b[39;49mcontainer_startup_health_check_timeout,\n\u001b[1;32m    324\u001b[0m     inference_recommendation_id\u001b[39m=\u001b[39;49minference_recommendation_id,\n\u001b[1;32m    325\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-experiments/lib/python3.10/site-packages/sagemaker/model.py:1183\u001b[0m, in \u001b[0;36mModel.deploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, async_inference_config, serverless_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, inference_recommendation_id, **kwargs)\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_base_name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1181\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_base_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_base_name, compiled_model_suffix))\n\u001b[0;32m-> 1183\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_sagemaker_model(\n\u001b[1;32m   1184\u001b[0m     instance_type, accelerator_type, tags, serverless_inference_config\n\u001b[1;32m   1185\u001b[0m )\n\u001b[1;32m   1187\u001b[0m serverless_inference_config_dict \u001b[39m=\u001b[39m (\n\u001b[1;32m   1188\u001b[0m     serverless_inference_config\u001b[39m.\u001b[39m_to_request_dict() \u001b[39mif\u001b[39;00m is_serverless \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m )\n\u001b[1;32m   1190\u001b[0m production_variant \u001b[39m=\u001b[39m sagemaker\u001b[39m.\u001b[39mproduction_variant(\n\u001b[1;32m   1191\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname,\n\u001b[1;32m   1192\u001b[0m     instance_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1198\u001b[0m     container_startup_health_check_timeout\u001b[39m=\u001b[39mcontainer_startup_health_check_timeout,\n\u001b[1;32m   1199\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-experiments/lib/python3.10/site-packages/sagemaker/model.py:688\u001b[0m, in \u001b[0;36mModel._create_sagemaker_model\u001b[0;34m(self, instance_type, accelerator_type, tags, serverless_inference_config)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_sagemaker_session_if_does_not_exist(instance_type)\n\u001b[1;32m    680\u001b[0m create_model_args \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m    681\u001b[0m     name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname,\n\u001b[1;32m    682\u001b[0m     role\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrole,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    686\u001b[0m     tags\u001b[39m=\u001b[39mtags,\n\u001b[1;32m    687\u001b[0m )\n\u001b[0;32m--> 688\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msagemaker_session\u001b[39m.\u001b[39;49mcreate_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcreate_model_args)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-experiments/lib/python3.10/site-packages/sagemaker/session.py:3057\u001b[0m, in \u001b[0;36mSession.create_model\u001b[0;34m(self, name, role, container_defs, vpc_config, enable_network_isolation, primary_container, tags)\u001b[0m\n\u001b[1;32m   3054\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3055\u001b[0m             \u001b[39mraise\u001b[39;00m\n\u001b[0;32m-> 3057\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_intercept_create_request(create_model_request, submit, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_model\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[1;32m   3058\u001b[0m \u001b[39mreturn\u001b[39;00m name\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-experiments/lib/python3.10/site-packages/sagemaker/session.py:4818\u001b[0m, in \u001b[0;36mSession._intercept_create_request\u001b[0;34m(self, request, create, func_name)\u001b[0m\n\u001b[1;32m   4805\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_intercept_create_request\u001b[39m(\n\u001b[1;32m   4806\u001b[0m     \u001b[39mself\u001b[39m, request: typing\u001b[39m.\u001b[39mDict, create, func_name: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[1;32m   4807\u001b[0m ):\n\u001b[1;32m   4808\u001b[0m     \u001b[39m\"\"\"This function intercepts the create job request.\u001b[39;00m\n\u001b[1;32m   4809\u001b[0m \n\u001b[1;32m   4810\u001b[0m \u001b[39m    PipelineSession inherits this Session class and will override\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4816\u001b[0m \u001b[39m        func_name (str): the name of the function needed intercepting\u001b[39;00m\n\u001b[1;32m   4817\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4818\u001b[0m     \u001b[39mreturn\u001b[39;00m create(request)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-experiments/lib/python3.10/site-packages/sagemaker/session.py:3045\u001b[0m, in \u001b[0;36mSession.create_model.<locals>.submit\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m   3043\u001b[0m LOGGER\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mCreateModel request: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, json\u001b[39m.\u001b[39mdumps(request, indent\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m))\n\u001b[1;32m   3044\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3045\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msagemaker_client\u001b[39m.\u001b[39;49mcreate_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrequest)\n\u001b[1;32m   3046\u001b[0m \u001b[39mexcept\u001b[39;00m ClientError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   3047\u001b[0m     error_code \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39mresponse[\u001b[39m\"\u001b[39m\u001b[39mError\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mCode\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-experiments/lib/python3.10/site-packages/botocore/client.py:530\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    527\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpy_operation_name\u001b[39m}\u001b[39;00m\u001b[39m() only accepts keyword arguments.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[1;32m    529\u001b[0m \u001b[39m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 530\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_api_call(operation_name, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-experiments/lib/python3.10/site-packages/botocore/client.py:960\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    958\u001b[0m     error_code \u001b[39m=\u001b[39m parsed_response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mError\u001b[39m\u001b[39m\"\u001b[39m, {})\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mCode\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    959\u001b[0m     error_class \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 960\u001b[0m     \u001b[39mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    961\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m     \u001b[39mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the CreateModel operation: Could not access model data at s3://aws-ml-blog/artifacts/pytorch-script-mode-local-model-inference/model.tar.gz. Please ensure that the role \"arn:aws:iam::908060038426:role/sagemaker-local-role\" exists and that its trust relationship policy allows the action \"sts:AssumeRole\" for the service principal \"sagemaker.amazonaws.com\". Also ensure that the role has \"s3:GetObject\" permissions and that the object is located in us-east-1."
     ]
    }
   ],
   "source": [
    "from sagemaker.local import LocalSession\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "print('AWS_PROFILE:', os.environ.get('AWS_PROFILE'))\n",
    "\n",
    "DUMMY_IAM_ROLE = 'arn:aws:iam::111111111111:role/service-role/AmazonSageMaker-ExecutionRole-20200101T000001'\n",
    "\n",
    "instance_type = \"local_gpu\"\n",
    "\n",
    "# hub = {\n",
    "#   'HF_MODEL_ID':'facebook/wav2vec2-large-960h-lv60-self',\n",
    "#   'HF_TASK':'AutomaticSpeechRecognitionPipeline'\n",
    "# }\n",
    "\n",
    "\n",
    "sagemaker_session = LocalSession()\n",
    "sagemaker_session.config = {'local': {'local_code': True}}\n",
    "\n",
    "model_dir = 's3://aws-ml-blog/artifacts/pytorch-script-mode-local-model-inference/model.tar.gz'\n",
    "\n",
    "model = HuggingFaceModel(\n",
    "    transformers_version='4.17',\n",
    "    pytorch_version='1.10',\n",
    "    py_version='py38',\n",
    "    # model_data='s3://my-trained-model/artifacts/model.tar.gz',\n",
    "    model_data=model_dir,\n",
    "    role=role,\n",
    "    # env=hub,\n",
    "    # sagemaker_session=sess,\n",
    ")\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='local',\n",
    ")\n",
    "\n",
    "# example request: you always need to define \"inputs\"\n",
    "# data = {\n",
    "#    \"inputs\": \"Camera - You are awarded a SiPix Digital Camera! call 09061221066 fromm landline. Delivery within 28 days.\"\n",
    "# }\n",
    "\n",
    "# # request\n",
    "# predictor.predict(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    transformers_version='4.6',\n",
    "    pytorch_version='1.7',\n",
    "    py_version='py36',\n",
    "    model_data='s3://my-trained-model/artifacts/model.tar.gz',\n",
    "    role=role,\n",
    ")\n",
    "# deploy model to SageMaker Inference\n",
    "huggingface_model.deploy(initial_instance_count=1,instance_type=\"ml.m5.xlarge\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c65e9e796324f01ccc2de1a4ebdf90e4cfd000cc4b64bd62190b1ef74c9ba484"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
