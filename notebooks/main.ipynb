{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([4], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X) \n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Linear weights: Parameter containing:\n",
      "tensor([[-0.0297, -0.0260,  0.0074,  ...,  0.0272, -0.0149, -0.0315],\n",
      "        [-0.0296,  0.0112,  0.0138,  ..., -0.0003,  0.0298,  0.0237],\n",
      "        [ 0.0068,  0.0220, -0.0161,  ...,  0.0206,  0.0108, -0.0067],\n",
      "        ...,\n",
      "        [-0.0082,  0.0343,  0.0086,  ..., -0.0318, -0.0265, -0.0214],\n",
      "        [ 0.0271, -0.0088,  0.0028,  ...,  0.0256, -0.0049,  0.0064],\n",
      "        [-0.0050,  0.0089, -0.0325,  ...,  0.0237, -0.0010,  0.0111]],\n",
      "       device='cuda:0', requires_grad=True) \n",
      "\n",
      "First Linear weights: Parameter containing:\n",
      "tensor([-1.4830e-02, -5.5940e-03,  2.3842e-02, -1.4581e-02,  1.4766e-02,\n",
      "        -2.1641e-02, -4.5917e-03, -3.4895e-02,  2.6124e-02,  6.0647e-03,\n",
      "        -6.2955e-03, -9.9045e-03,  3.3280e-03, -3.3120e-02, -2.6642e-02,\n",
      "        -2.5042e-02,  3.1486e-02,  6.2855e-03,  9.0678e-03,  2.3668e-02,\n",
      "        -2.2036e-02,  3.4410e-02,  1.9549e-02, -8.4453e-03,  3.0602e-02,\n",
      "         1.8247e-02, -3.3615e-02,  1.8675e-02, -5.7868e-03, -2.0086e-02,\n",
      "         3.3478e-02,  1.7680e-03, -2.8548e-02,  4.6137e-03,  3.2169e-02,\n",
      "         1.0300e-02, -7.9202e-03, -3.8397e-03, -1.7094e-02,  2.7045e-02,\n",
      "        -1.5628e-04,  3.0233e-02, -2.4422e-02,  2.2301e-02, -5.9311e-05,\n",
      "        -1.1588e-02, -2.7812e-02, -6.8993e-03,  7.8336e-03, -1.6508e-02,\n",
      "         7.2009e-03, -1.2390e-02,  1.9946e-02, -9.6646e-03,  6.0517e-03,\n",
      "         5.4372e-03,  2.5395e-02, -1.8581e-02, -1.1587e-02,  3.8893e-03,\n",
      "        -1.1380e-02,  1.8473e-02, -2.0874e-02,  1.8372e-02, -3.2386e-02,\n",
      "         1.9506e-02,  2.3086e-02, -1.0321e-02,  1.7453e-03, -7.4321e-03,\n",
      "        -3.4476e-02,  2.6838e-02,  1.2844e-02,  4.5135e-03, -2.9547e-03,\n",
      "         6.1724e-03, -2.0792e-02,  3.4959e-02, -3.2815e-02, -3.4762e-02,\n",
      "        -2.8902e-03,  6.2559e-03,  1.6508e-02,  1.0617e-02, -2.5360e-02,\n",
      "        -1.6939e-04,  3.9082e-03,  1.9290e-02,  7.5790e-03,  1.9351e-02,\n",
      "        -2.9815e-02,  1.8485e-02, -1.8227e-02,  1.4971e-02,  7.7211e-04,\n",
      "         2.5015e-02,  1.8799e-02,  3.4024e-02,  7.0412e-03,  1.9121e-02,\n",
      "         2.8526e-02,  1.7067e-02, -2.1174e-02, -9.0716e-03, -7.8844e-03,\n",
      "         2.6381e-02,  1.7188e-03,  3.1636e-02, -3.1881e-02, -1.8886e-02,\n",
      "        -9.6500e-03, -1.4347e-02,  3.7508e-03,  3.1147e-02, -1.4770e-02,\n",
      "         2.0981e-02,  1.5162e-02,  2.6744e-02,  3.1024e-02, -1.5726e-02,\n",
      "        -2.9848e-02,  2.4184e-02, -1.5790e-02,  5.1403e-03,  2.5786e-02,\n",
      "        -3.3191e-02, -4.0252e-03,  3.6021e-03, -2.9822e-02,  3.3182e-03,\n",
      "         1.6167e-02,  2.2805e-02, -1.7508e-02,  2.1120e-03,  2.9430e-03,\n",
      "        -4.4649e-03, -8.9733e-03,  9.1155e-03, -1.6745e-02,  2.4042e-02,\n",
      "        -3.5212e-02,  1.5375e-02, -2.7444e-02,  2.2140e-02, -2.1103e-02,\n",
      "         1.7183e-03,  3.9731e-03,  2.7344e-03, -1.5918e-02, -2.9353e-03,\n",
      "        -2.0865e-02,  1.9340e-02,  1.6984e-02, -3.2465e-02, -2.1512e-02,\n",
      "        -1.3234e-03, -1.0362e-02, -3.3663e-02,  3.1042e-02,  6.5122e-05,\n",
      "        -2.9174e-02,  1.1512e-02,  1.1937e-03,  4.1736e-03,  1.9847e-02,\n",
      "         1.3233e-02, -1.2063e-03,  2.3482e-02,  3.2009e-03,  2.7349e-02,\n",
      "        -3.4691e-03,  1.5343e-02,  2.3782e-02, -9.1494e-04,  9.1676e-03,\n",
      "        -2.9590e-02, -1.7399e-02,  2.5776e-02,  8.5395e-03, -3.4761e-02,\n",
      "        -2.8076e-04, -2.8815e-03, -2.1922e-02, -2.8653e-02, -1.8533e-02,\n",
      "        -3.6310e-03,  1.8961e-03,  1.5275e-02,  2.0459e-02,  3.4530e-03,\n",
      "         1.3068e-02,  1.0413e-02, -2.2406e-02,  2.1493e-02,  2.2526e-02,\n",
      "        -2.3395e-02, -1.7669e-03, -3.3920e-02, -2.0041e-02, -2.0106e-02,\n",
      "         1.5150e-02, -1.9728e-02, -1.4772e-02, -3.1005e-02, -3.4701e-02,\n",
      "         3.1432e-02, -2.2726e-02, -5.9366e-03,  6.5913e-03, -1.6755e-02,\n",
      "        -2.4733e-02, -6.4298e-03, -2.2907e-02,  2.5580e-02,  2.0341e-02,\n",
      "        -2.2969e-02,  8.6093e-03, -2.3249e-02, -1.9110e-02,  2.8332e-02,\n",
      "         3.2906e-02, -2.1755e-02, -3.8607e-05,  2.3770e-02, -6.5815e-03,\n",
      "        -2.1691e-02, -2.9100e-02,  2.5949e-02, -3.3729e-03, -2.6659e-02,\n",
      "         2.8728e-02,  2.3127e-02,  8.0784e-03, -3.1530e-03,  3.6025e-03,\n",
      "        -1.7909e-02, -2.0437e-02,  3.1051e-02,  2.8357e-02, -3.5196e-02,\n",
      "        -1.7944e-02,  2.4490e-02,  2.8822e-02, -1.5946e-02, -2.3405e-02,\n",
      "         7.3428e-03,  2.2607e-02, -2.7064e-02, -1.2503e-02, -1.7266e-02,\n",
      "         2.0183e-02,  9.8585e-03, -1.9789e-02,  6.8773e-03, -2.2725e-03,\n",
      "        -1.2434e-02,  1.1165e-02,  6.5627e-03,  1.2410e-02,  3.1567e-02,\n",
      "         9.8152e-03, -1.2768e-02, -3.4997e-02,  3.3263e-03,  1.8198e-02,\n",
      "        -2.5205e-02,  2.0269e-02,  3.0080e-02, -3.9664e-03,  3.0160e-02,\n",
      "         6.0962e-04,  1.6705e-02, -2.2744e-02, -7.4631e-03,  4.5625e-03,\n",
      "        -2.3781e-02, -3.4279e-02, -1.4473e-02,  1.9243e-02,  2.8204e-03,\n",
      "        -2.9256e-03, -1.4916e-02, -3.2010e-02,  1.8622e-03,  1.1978e-03,\n",
      "         6.5386e-03, -1.6069e-02,  2.7856e-02,  4.9137e-03, -1.0284e-02,\n",
      "        -2.4501e-02,  2.3462e-02, -3.2830e-02,  1.6715e-03,  8.8392e-03,\n",
      "        -8.5850e-03, -2.1567e-02, -3.4296e-02, -2.3642e-02, -1.6132e-02,\n",
      "        -8.3725e-03, -2.9139e-02, -4.5121e-03, -1.9375e-02,  1.4583e-02,\n",
      "        -2.6471e-02,  5.3004e-03, -1.7877e-02,  3.3867e-03,  1.6845e-02,\n",
      "         2.4218e-02,  2.9463e-02,  1.4272e-02, -3.4257e-02, -1.6867e-02,\n",
      "        -4.6643e-03,  1.5116e-02,  1.9135e-02,  3.2175e-02, -1.8533e-02,\n",
      "         7.0337e-03,  1.3243e-02, -2.4113e-02,  3.2884e-02, -2.3050e-02,\n",
      "         2.2204e-02,  3.3987e-02,  1.9247e-02,  2.1030e-03, -3.0835e-02,\n",
      "        -3.0969e-03,  2.2362e-02, -3.4017e-02,  8.9139e-03, -2.2291e-02,\n",
      "        -2.9801e-02, -1.5694e-02,  1.8249e-02, -5.9849e-03, -1.4206e-02,\n",
      "        -2.6034e-02,  3.6078e-03, -2.3305e-04, -1.2565e-02, -1.2371e-02,\n",
      "         2.8204e-02,  1.5165e-02,  2.9249e-02, -8.0954e-04, -1.8053e-02,\n",
      "         2.4914e-02,  2.3540e-02,  1.7112e-02, -2.0944e-02, -3.2591e-02,\n",
      "        -2.6829e-02, -1.6405e-02, -4.7589e-03, -2.7606e-03,  1.2033e-02,\n",
      "         2.0841e-02,  2.1078e-03, -1.7010e-03,  9.4715e-04,  1.7343e-03,\n",
      "         1.8733e-02,  2.9164e-02, -3.0187e-02,  2.8911e-02, -2.7604e-02,\n",
      "        -1.0821e-02,  2.7406e-02, -3.2608e-02,  3.1603e-02,  1.4090e-02,\n",
      "        -4.3070e-03,  1.8406e-02, -2.2264e-02,  3.0883e-02, -3.5686e-02,\n",
      "         3.3643e-02,  2.9372e-02,  2.0625e-02,  1.6805e-02,  4.9024e-04,\n",
      "        -2.1799e-02, -1.6073e-02, -6.9265e-03,  1.1616e-02,  3.4635e-02,\n",
      "         1.0304e-02,  1.9443e-02, -1.4357e-02,  1.2368e-02, -1.2263e-02,\n",
      "        -2.4759e-02, -3.4403e-02,  3.5062e-02,  1.5213e-02, -1.5484e-02,\n",
      "        -2.6858e-02,  2.3432e-02,  2.7709e-02,  2.7913e-02, -2.7623e-02,\n",
      "        -3.1824e-03, -3.5239e-02,  7.9128e-03, -3.0842e-02,  9.9177e-03,\n",
      "        -9.7347e-03,  2.0579e-02, -1.0970e-02, -6.2386e-03, -5.8191e-03,\n",
      "         3.3943e-03, -5.6003e-03, -1.5106e-02, -3.3339e-02,  9.3835e-03,\n",
      "         2.2780e-02,  3.0143e-02, -1.6495e-02, -2.8882e-02, -1.3347e-02,\n",
      "        -1.8693e-02, -2.8332e-02,  3.1118e-02, -1.3983e-02, -3.2440e-02,\n",
      "        -1.8024e-02,  8.6751e-03,  1.9047e-02,  2.5771e-03,  3.2077e-02,\n",
      "        -1.6786e-02,  6.2911e-04,  6.9853e-03, -2.4019e-03, -3.7018e-03,\n",
      "         9.2780e-03,  2.3528e-02, -1.1447e-02, -1.2022e-02,  2.9863e-02,\n",
      "         2.9587e-02,  2.6175e-02,  2.7476e-03, -1.0338e-02, -2.7910e-02,\n",
      "         2.3576e-02,  4.2908e-04, -1.9547e-03, -3.0297e-02, -2.1400e-02,\n",
      "        -3.6028e-03, -3.5185e-02, -2.6804e-02,  2.4837e-02,  1.6333e-02,\n",
      "         1.7652e-02,  6.8995e-03,  1.0495e-02,  6.5412e-03, -2.1523e-02,\n",
      "         8.7895e-03,  2.3389e-03,  2.0093e-03, -2.5367e-02, -2.3581e-02,\n",
      "        -8.9211e-03,  6.6166e-04,  1.0159e-02,  1.6566e-02, -1.4754e-02,\n",
      "        -1.7294e-02, -2.8359e-03,  1.4067e-02,  7.4536e-03,  1.9748e-02,\n",
      "         1.6011e-03,  3.3011e-02,  3.2477e-02, -5.3816e-03, -2.3996e-02,\n",
      "         1.4112e-02, -8.7352e-03,  2.7904e-02,  1.4073e-02, -2.0922e-02,\n",
      "        -1.5491e-02,  1.4951e-02, -1.2447e-02,  9.7471e-04,  8.8422e-03,\n",
      "         2.6567e-02,  1.5837e-02, -4.5185e-03,  3.0488e-02, -2.2310e-02,\n",
      "         1.7380e-03,  1.3593e-02,  3.3054e-02, -7.4752e-03,  2.1604e-03,\n",
      "        -1.0194e-02, -2.0133e-03,  8.0902e-03,  8.9521e-03,  6.1632e-03,\n",
      "        -1.4923e-02, -1.2404e-02], device='cuda:0', requires_grad=True) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"First Linear weights: {model.linear_relu_stack[0].weight} \\n\")\n",
    "\n",
    "print(f\"First Linear weights: {model.linear_relu_stack[0].bias} \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c65e9e796324f01ccc2de1a4ebdf90e4cfd000cc4b64bd62190b1ef74c9ba484"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
