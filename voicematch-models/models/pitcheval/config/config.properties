# https://github.com/pytorch/serve/blob/master/docs/configuration.md
enable_envvars_config=true
decode_input_request=false
load_models=ALL
default_response_timeout=20
inference_address=http://0.0.0.0:8080
management_address=http://0.0.0.0:8080
# grpc_inference_port=7070
# grpc_management_port=7071
default_service_handler=/opt/conda/lib/python3.9/site-packages/sagemaker_pytorch_serving_container/handler_service.py:handle
default_workers_per_model=4
